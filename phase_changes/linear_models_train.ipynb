{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Linear One-Neuron Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is for training 100,000 one-neuron models with varying levels of sparsity and different loss functions. The differences in loss functions is described in the replication paper found <a href=\"https://github.com/zroe1/toy_models_of_superposition/blob/main/FINDINGS.pdf\">here.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N_xq8u-hOV0F"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import warnings\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uczueOklOZmY",
    "outputId": "10e63d21-af61-45eb-b158-5f7a892e8dea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\"\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xKisAzQXOiI4"
   },
   "outputs": [],
   "source": [
    "class ManyToyModels(nn.Module):\n",
    "    def __init__(self, m, n, num_models, include_ReLU):\n",
    "        '''Create a toy model\n",
    "\n",
    "        Args:\n",
    "            m (int): the number of neurons (as described in original paper)\n",
    "            n (int): the number of features the Toy model can map.\n",
    "            (The weight matrix is delcared to be m * n)\n",
    "\n",
    "            include_ReLU (bool): if True, a nonlinearity is added to the network\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(num_models, m, n), requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.randn(num_models, n, 1), requires_grad=True)\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        self.inclue_ReLU = include_ReLU\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.weights @ x\n",
    "        final = torch.transpose(self.weights, -2, -1) @ hidden\n",
    "        final += self.bias\n",
    "        if self.inclue_ReLU:\n",
    "            return self.ReLU(final)\n",
    "        else:\n",
    "            return final\n",
    "\n",
    "class MSE_Multiple_models(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MSE_Multiple_models, self).__init__()\n",
    "\n",
    "    def forward(self, predictions, targets, importance):\n",
    "        sub_total = ((predictions - targets)**2).sum(0)\n",
    "        return torch.sum(sub_total * importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5HNMvQdmOkjb"
   },
   "outputs": [],
   "source": [
    "sparsity_rows = 1000\n",
    "importance_rows = 100\n",
    "probs = torch.repeat_interleave((torch.arange(0, sparsity_rows) / sparsity_rows), 2 * importance_rows)\n",
    "probs = probs.reshape(sparsity_rows * importance_rows, 1, 2)\n",
    "\n",
    "def train_1000_models(model, num_models, epochs, total_batchs, batch_size, loss_fn, optimizer, importance):\n",
    "    model.train()\n",
    "    loss_total = 0\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batchs):\n",
    "            # calculating sparsity based on model\n",
    "            rand_tensor = torch.rand(sparsity_rows * importance_rows, 1, 2)\n",
    "            sparsity_tensor = (probs > rand_tensor).float()\n",
    "\n",
    "            x = torch.rand(batch_size, num_models, 2, 1)\n",
    "            x = (x*sparsity_tensor).to(device)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, x, importance)\n",
    "            loss_total += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print(\"(EPOCH:\", str(epoch + 1) + \")\", \"--> loss:\", loss_total / (total_batchs * batch_size))\n",
    "        loss_total = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training 100,000 Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "ROsMK7XOOmxj"
   },
   "outputs": [],
   "source": [
    "model_test = ManyToyModels(1, 2, 100000, False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "AvEPet13Oob_"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "BATCHS_PER_EPOCH = 100\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "YR23CBMXOr7m"
   },
   "outputs": [],
   "source": [
    "first_feature_importance = torch.ones(100000, 1)\n",
    "second_feature_importance = ((torch.arange(100)).repeat(1000, 1) / 10).reshape(100000, 1)\n",
    "IMPORTANCE = torch.stack((first_feature_importance, second_feature_importance), dim=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d22_-GedO8Dz",
    "outputId": "6e2d0114-6a91-4f82-b5db-5fde51b939e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(EPOCH: 1) --> loss: 772262.775\n",
      "(EPOCH: 2) --> loss: 161320.47046875\n",
      "(EPOCH: 3) --> loss: 64857.8904296875\n",
      "(EPOCH: 4) --> loss: 36746.720546875\n",
      "(EPOCH: 5) --> loss: 25857.49462890625\n",
      "(EPOCH: 6) --> loss: 20756.72845703125\n",
      "(EPOCH: 7) --> loss: 18014.30462890625\n",
      "(EPOCH: 8) --> loss: 16400.17115234375\n",
      "(EPOCH: 9) --> loss: 15399.145771484375\n",
      "(EPOCH: 10) --> loss: 14749.794599609375\n",
      "(EPOCH: 11) --> loss: 14311.428212890625\n",
      "(EPOCH: 12) --> loss: 14005.14705078125\n",
      "(EPOCH: 13) --> loss: 13793.63736328125\n",
      "(EPOCH: 14) --> loss: 13630.862958984375\n",
      "(EPOCH: 15) --> loss: 13522.014208984376\n",
      "(EPOCH: 16) --> loss: 13428.155712890624\n",
      "(EPOCH: 17) --> loss: 13361.977666015626\n",
      "(EPOCH: 18) --> loss: 13313.62705078125\n",
      "(EPOCH: 19) --> loss: 13266.664765625\n",
      "(EPOCH: 20) --> loss: 13235.67900390625\n",
      "(EPOCH: 21) --> loss: 13209.346044921875\n",
      "(EPOCH: 22) --> loss: 13188.49134765625\n",
      "(EPOCH: 23) --> loss: 13177.616171875\n",
      "(EPOCH: 24) --> loss: 13170.730908203124\n",
      "(EPOCH: 25) --> loss: 13155.586591796875\n",
      "(EPOCH: 26) --> loss: 13147.834609375\n",
      "(EPOCH: 27) --> loss: 13144.030458984374\n",
      "(EPOCH: 28) --> loss: 13140.792431640624\n",
      "(EPOCH: 29) --> loss: 13137.742265625\n",
      "(EPOCH: 30) --> loss: 13133.289794921875\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model_test.parameters(), lr=LEARNING_RATE)\n",
    "loss_func = MSE_Multiple_models()\n",
    "num_models = 100000\n",
    "\n",
    "train_1000_models(model_test, num_models, NUM_EPOCHS, BATCHS_PER_EPOCH, BATCH_SIZE, loss_func, optimizer, IMPORTANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bTIMn3jKVLno",
    "outputId": "b8982bd9-bfe8-473a-9133-1661e998e3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(EPOCH: 1) --> loss: 13186.568330078126\n",
      "(EPOCH: 2) --> loss: 13159.0689453125\n",
      "(EPOCH: 3) --> loss: 13161.2562890625\n",
      "(EPOCH: 4) --> loss: 13159.626455078125\n",
      "(EPOCH: 5) --> loss: 13162.96458984375\n",
      "(EPOCH: 6) --> loss: 13160.20685546875\n",
      "(EPOCH: 7) --> loss: 13161.143837890624\n",
      "(EPOCH: 8) --> loss: 13159.79759765625\n",
      "(EPOCH: 9) --> loss: 13162.392265625\n",
      "(EPOCH: 10) --> loss: 13163.2719140625\n",
      "(EPOCH: 11) --> loss: 13161.98828125\n",
      "(EPOCH: 12) --> loss: 13165.759794921874\n",
      "(EPOCH: 13) --> loss: 13161.02978515625\n",
      "(EPOCH: 14) --> loss: 13162.150400390625\n",
      "(EPOCH: 15) --> loss: 13161.86771484375\n",
      "(EPOCH: 16) --> loss: 13163.25552734375\n",
      "(EPOCH: 17) --> loss: 13161.348935546876\n",
      "(EPOCH: 18) --> loss: 13160.00740234375\n",
      "(EPOCH: 19) --> loss: 13161.131328125\n",
      "(EPOCH: 20) --> loss: 13163.4822265625\n",
      "(EPOCH: 21) --> loss: 13160.15080078125\n",
      "(EPOCH: 22) --> loss: 13165.15166015625\n",
      "(EPOCH: 23) --> loss: 13159.871123046874\n",
      "(EPOCH: 24) --> loss: 13160.26337890625\n",
      "(EPOCH: 25) --> loss: 13163.285830078124\n",
      "(EPOCH: 26) --> loss: 13162.858857421876\n",
      "(EPOCH: 27) --> loss: 13163.5047265625\n",
      "(EPOCH: 28) --> loss: 13162.01416015625\n",
      "(EPOCH: 29) --> loss: 13164.847412109375\n",
      "(EPOCH: 30) --> loss: 13163.80177734375\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model_test.parameters(), lr=LEARNING_RATE)\n",
    "loss_func = MSE_Multiple_models()\n",
    "num_models = 100000\n",
    "\n",
    "train_1000_models(model_test, num_models, NUM_EPOCHS, BATCHS_PER_EPOCH, BATCH_SIZE, loss_func, optimizer, IMPORTANCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "pzADWYWyO9v5"
   },
   "outputs": [],
   "source": [
    "w = model_test.weights.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "HRPyS-FIQtFD"
   },
   "outputs": [],
   "source": [
    "w = w.reshape(1000, 100, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "-WivQDXnQvZy"
   },
   "outputs": [],
   "source": [
    "model_first_feature = ((torch.abs(w[:,:,:, :1]) > 0.8) & (torch.abs(w[:,:,:, 1:2]) < 0.2)).squeeze()\n",
    "model_second_feature = ((torch.abs(w[:,:,:, :1]) < 0.2) & (torch.abs(w[:,:,:, 1:2]) > 0.8)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "A9WutLnVQ0X4"
   },
   "outputs": [],
   "source": [
    "measured_losses = torch.zeros(1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "biXY84WBQ0tq"
   },
   "outputs": [],
   "source": [
    "measured_losses[model_first_feature] = 1\n",
    "measured_losses[model_second_feature] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "ufkuCDBbQ2Dh",
    "outputId": "3210e009-d7ac-459a-ccb1-7d9cc4c4ddd9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 450x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.figure(figsize=(3, 3), dpi=150)\n",
    "\n",
    "# Set the x-axis to a logarithmic scale\n",
    "plt.gca().set_xscale('log')\n",
    "plt.gca().set_yscale('log')\n",
    "\n",
    "colors = [(.4, 0, 1), (1, 1, 1), (1, .4, 0)]  # Purple -> White -> Orange\n",
    "n_bins = 100\n",
    "cm = LinearSegmentedColormap.from_list(\"\", colors, N=n_bins)\n",
    "\n",
    "plt.imshow(measured_losses, cmap=cm, aspect='auto')\n",
    "\n",
    "# Get current y-ticks\n",
    "current_yticks = plt.gca().get_yticks()\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.gca().set_xticklabels(['', '', '0.1', '1', '10', '', ''])\n",
    "plt.gca().set_yticklabels(['', '', '0.1', '0.1', ''])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yqdwo3_aHxP_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
