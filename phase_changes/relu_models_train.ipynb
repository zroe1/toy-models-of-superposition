{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "N_xq8u-hOV0F"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import warnings\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uczueOklOZmY",
    "outputId": "b931c8cd-04e6-47de-ccba-fd70e9f2d22f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\"\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xKisAzQXOiI4"
   },
   "outputs": [],
   "source": [
    "class ManyToyModels(nn.Module):\n",
    "    def __init__(self, m, n, num_models, include_ReLU):\n",
    "        '''Create a toy model\n",
    "\n",
    "        Args:\n",
    "            m (int): the number of neurons (as described in original paper)\n",
    "            n (int): the number of features the Toy model can map.\n",
    "            (The weight matrix is delcared to be m * n)\n",
    "\n",
    "            include_ReLU (bool): if True, a nonlinearity is added to the network\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(num_models, m, n) * 1.5, requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.randn(num_models, n, 1) * 0.5, requires_grad=True)\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        self.inclue_ReLU = include_ReLU\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.weights @ x\n",
    "        final = torch.transpose(self.weights, -2, -1) @ hidden\n",
    "        final += self.bias\n",
    "        if self.inclue_ReLU:\n",
    "            return self.ReLU(final)\n",
    "        else:\n",
    "            return final\n",
    "\n",
    "class MSE_Multiple_models(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MSE_Multiple_models, self).__init__()\n",
    "\n",
    "    def forward(self, predictions, targets, importance):\n",
    "        sub_total = ((predictions - targets)**2).sum(0)\n",
    "        return torch.sum(sub_total * importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5HNMvQdmOkjb"
   },
   "outputs": [],
   "source": [
    "sparsity_rows = 1000\n",
    "importance_rows = 100\n",
    "probs = torch.repeat_interleave((torch.arange(0, sparsity_rows) / sparsity_rows), 2 * importance_rows)\n",
    "probs = probs.reshape(sparsity_rows * importance_rows, 1, 2)\n",
    "\n",
    "def train_1000_models(model, num_models, epochs, total_batchs, batch_size, loss_fn, optimizer, importance):\n",
    "\n",
    "    model.train()\n",
    "    loss_total = 0\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batchs):\n",
    "            # calculating sparsity based on model\n",
    "            rand_tensor = torch.rand(sparsity_rows * importance_rows, 1, 2)\n",
    "            sparsity_tensor = (probs > rand_tensor).float()\n",
    "\n",
    "            x = torch.rand(batch_size, num_models, 2, 1)\n",
    "            x = (x*sparsity_tensor).to(device)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, x, importance)\n",
    "            loss_total += loss.item()  / (total_batchs * batch_size)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print(\"(EPOCH:\", str(epoch + 1) + \")\", \"--> loss:\", loss_total)\n",
    "        loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ROsMK7XOOmxj"
   },
   "outputs": [],
   "source": [
    "model_test = ManyToyModels(1, 2, 100000, True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "AvEPet13Oob_"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 6\n",
    "BATCHS_PER_EPOCH = 1000\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "YR23CBMXOr7m"
   },
   "outputs": [],
   "source": [
    "first_feature_importance = torch.ones(100000, 1)\n",
    "second_feature_importance = ((torch.arange(100)).repeat(1000, 1) / 10).reshape(100000, 1)\n",
    "IMPORTANCE = torch.stack((first_feature_importance, second_feature_importance), dim=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d22_-GedO8Dz",
    "outputId": "b21e8ec1-57b1-4bb3-f423-89559d661729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(EPOCH: 1) --> loss: 245705.2817851561\n",
      "(EPOCH: 2) --> loss: 39223.08166796875\n",
      "(EPOCH: 3) --> loss: 34123.73390429686\n",
      "(EPOCH: 4) --> loss: 31683.03798242184\n",
      "(EPOCH: 5) --> loss: 30337.919716796867\n",
      "(EPOCH: 6) --> loss: 29573.83727148439\n",
      "**************************************************\n",
      "(EPOCH: 1) --> loss: 255647.09587890652\n",
      "(EPOCH: 2) --> loss: 39794.02270312497\n",
      "(EPOCH: 3) --> loss: 34726.279933593745\n",
      "(EPOCH: 4) --> loss: 32295.809681640647\n",
      "(EPOCH: 5) --> loss: 30937.214037109363\n",
      "(EPOCH: 6) --> loss: 30166.45762695311\n",
      "**************************************************\n",
      "(EPOCH: 1) --> loss: 246156.64471093766\n",
      "(EPOCH: 2) --> loss: 39392.51835156255\n",
      "(EPOCH: 3) --> loss: 34350.718603515634\n",
      "(EPOCH: 4) --> loss: 31920.517179687486\n",
      "(EPOCH: 5) --> loss: 30546.185976562538\n",
      "(EPOCH: 6) --> loss: 29744.95558789068\n",
      "**************************************************\n",
      "(EPOCH: 1) --> loss: 250382.6378515623\n",
      "(EPOCH: 2) --> loss: 39873.45719921876\n",
      "(EPOCH: 3) --> loss: 34688.636535156234\n",
      "(EPOCH: 4) --> loss: 32187.924908203167\n",
      "(EPOCH: 5) --> loss: 30802.904019531252\n",
      "(EPOCH: 6) --> loss: 30021.856761718795\n",
      "**************************************************\n",
      "(EPOCH: 1) --> loss: 252871.3494921878\n",
      "(EPOCH: 2) --> loss: 39430.11249218749\n",
      "(EPOCH: 3) --> loss: 34412.729187500016\n",
      "(EPOCH: 4) --> loss: 31955.15791992183\n",
      "(EPOCH: 5) --> loss: 30533.405884765627\n",
      "(EPOCH: 6) --> loss: 29715.832193359423\n",
      "**************************************************\n",
      "(EPOCH: 1) --> loss: 252349.7622382808\n",
      "(EPOCH: 2) --> loss: 39802.89350390629\n",
      "(EPOCH: 3) --> loss: 34746.862433593735\n",
      "(EPOCH: 4) --> loss: 32280.438605468775\n",
      "(EPOCH: 5) --> loss: 30873.55958398441\n",
      "(EPOCH: 6) --> loss: 30079.180919921837\n",
      "**************************************************\n",
      "(EPOCH: 1) --> loss: 254800.67554687485\n",
      "(EPOCH: 2) --> loss: 39578.02952343751\n",
      "(EPOCH: 3) --> loss: 34473.25686523439\n",
      "(EPOCH: 4) --> loss: 31979.887779296845\n",
      "(EPOCH: 5) --> loss: 30561.297937499985\n",
      "(EPOCH: 6) --> loss: 29789.045957031274\n",
      "**************************************************\n",
      "(EPOCH: 1) --> loss: 250716.59244531245\n",
      "(EPOCH: 2) --> loss: 39530.38233984374\n",
      "(EPOCH: 3) --> loss: 34486.758097656246\n",
      "(EPOCH: 4) --> loss: 31976.15763867188\n",
      "(EPOCH: 5) --> loss: 30552.88396484377\n",
      "(EPOCH: 6) --> loss: 29765.59380859376\n",
      "**************************************************\n",
      "(EPOCH: 1) --> loss: 245378.47779687488\n",
      "(EPOCH: 2) --> loss: 39547.16179687502\n",
      "(EPOCH: 3) --> loss: 34473.453542968775\n",
      "(EPOCH: 4) --> loss: 32016.999669921865\n",
      "(EPOCH: 5) --> loss: 30637.10235351561\n",
      "(EPOCH: 6) --> loss: 29861.227462890623\n",
      "**************************************************\n",
      "(EPOCH: 1) --> loss: 248203.93621093704\n",
      "(EPOCH: 2) --> loss: 39273.12078125003\n",
      "(EPOCH: 3) --> loss: 34257.8961503906\n",
      "(EPOCH: 4) --> loss: 31770.841478515616\n",
      "(EPOCH: 5) --> loss: 30365.813812499993\n",
      "(EPOCH: 6) --> loss: 29568.697757812526\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "weights_total = None\n",
    "NUM_MODELS_TO_AVG_OVER = 10\n",
    "\n",
    "for i in range(NUM_MODELS_TO_AVG_OVER):\n",
    "  model_test = ManyToyModels(1, 2, 100000, True).to(device)\n",
    "  optimizer = torch.optim.Adam(model_test.parameters(), lr=LEARNING_RATE)\n",
    "  loss_func = MSE_Multiple_models()\n",
    "  num_models = 100000\n",
    "\n",
    "  train_1000_models(model_test, num_models, NUM_EPOCHS, BATCHS_PER_EPOCH, BATCH_SIZE, loss_func, optimizer, IMPORTANCE)\n",
    "  # w = model_test.weights.to('cpu')\n",
    "\n",
    "  w = model_test.weights.to('cpu').reshape(1000, 100, 1, 2)\n",
    "\n",
    "  if weights_total is None:\n",
    "    weights_total = [w]\n",
    "  else:\n",
    "    weights_total.append(w)\n",
    "\n",
    "  print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_avgs = None\n",
    "for weights in weights_total:\n",
    "    measured_losses = torch.zeros(1000, 100)\n",
    "    model_first_feature = ((torch.abs(weights[:,:,:, :1]) > 0.8) & (torch.abs(weights[:,:,:, 1:2]) < 0.2)).squeeze()\n",
    "    model_second_feature = ((torch.abs(weights[:,:,:, :1]) < 0.2) & (torch.abs(weights[:,:,:, 1:2]) > 0.8)).squeeze()\n",
    "    measured_losses[model_first_feature] = 1\n",
    "    measured_losses[model_second_feature] = -1\n",
    "\n",
    "    if w_avgs == None:\n",
    "        w_avgs = measured_losses\n",
    "    else:\n",
    "        w_avgs += measured_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "kROlHVqOeOGh"
   },
   "outputs": [],
   "source": [
    "model_first_feature = (w_avgs > 5).squeeze() # mapped by 1\n",
    "model_second_feature = (w_avgs < -5).squeeze() # mapped by -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "Z0ulUzwXej9_"
   },
   "outputs": [],
   "source": [
    "avgs_graph= torch.zeros(1000, 100)\n",
    "avgs_graph[model_first_feature] = 1\n",
    "avgs_graph[model_second_feature] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "iagsqXgjeqcx"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 450x450 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.figure(figsize=(3, 3), dpi=150)\n",
    "\n",
    "# Set the x-axis to a logarithmic scale\n",
    "plt.gca().set_xscale('log')\n",
    "plt.gca().set_yscale('log')\n",
    "\n",
    "colors = [(.4, 0, 1), (1, 1, 1), (1, .4, 0)]  # Purple -> White -> Orange\n",
    "n_bins = 100\n",
    "cm = LinearSegmentedColormap.from_list(\"\", colors, N=n_bins)\n",
    "\n",
    "plt.imshow(avgs_graph, cmap=cm, aspect='auto')\n",
    "\n",
    "# Get current y-ticks\n",
    "current_yticks = plt.gca().get_yticks()\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.gca().set_xticklabels(['', '', '0.1', '1', '10', '', ''])\n",
    "plt.gca().set_yticklabels(['', '', '0.1', '0.1', ''])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4zcVxguw1Cs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
