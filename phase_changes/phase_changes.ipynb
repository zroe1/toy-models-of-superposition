{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bce69ef-d43b-4888-a7cd-2370ef0f2870",
   "metadata": {},
   "source": [
    "# Theoretical Phase Changes in 1 Neuron Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76e23148-6341-463b-92e0-d5268dabf4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import warnings\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "e60d0c64-8206-4b9b-b135-afef96d5b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1(s):\n",
    "  return (s/3) - (s*s)/4\n",
    "\n",
    "def l2(s, r):\n",
    "  return r * ((s/3) - (s*s)/4)\n",
    "\n",
    "def l3(s, r):\n",
    "  return ((1 + r) * s*s) / 6\n",
    "\n",
    "# Create a tensor\n",
    "rv = torch.zeros(1000, 100)\n",
    "\n",
    "# Create grids\n",
    "i, j = torch.meshgrid(torch.arange(1000), torch.arange(100), indexing='ij')\n",
    "\n",
    "# Calculate s and r for the entire grid\n",
    "s = (i) / 1000\n",
    "r = j / 10\n",
    "\n",
    "# Apply the functions\n",
    "l1_result = l1(s)\n",
    "l2_result = l2(s, r)\n",
    "l3_result = l3(s, r)\n",
    "\n",
    "# Apply the custom min logic\n",
    "condition1 = torch.le(l1_result, l2_result) & torch.le(l1_result, l3_result)\n",
    "condition2 = torch.le(l2_result, l1_result) & torch.le(l2_result, l3_result)\n",
    "\n",
    "rv[condition1] = -1\n",
    "rv[condition2] = 1\n",
    "rv[~condition1 & ~condition2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "f7f0e864-a077-4155-bc42-cf81069618c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 450x450 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.figure(figsize=(3, 3), dpi=150)\n",
    "\n",
    "# Set the x-axis to a logarithmic scale\n",
    "plt.gca().set_xscale('log')\n",
    "plt.gca().set_yscale('log')\n",
    "\n",
    "colors = [(.4, 0, 1), (1, 1, 1), (1, .4, 0)]  # Purple -> White -> Orange\n",
    "n_bins = 100 \n",
    "cm = LinearSegmentedColormap.from_list(\"\", colors, N=n_bins)\n",
    "\n",
    "plt.imshow(rv, cmap=cm, aspect='auto')\n",
    "\n",
    "# Get current y-ticks\n",
    "current_yticks = plt.gca().get_yticks()\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.gca().set_xticklabels(['', '', '0.1', '1', '10', '', ''])\n",
    "plt.gca().set_yticklabels(['', '', '0.1', '0.1', ''])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c01d70-14a4-4a6b-b47a-a9b897619370",
   "metadata": {},
   "source": [
    "# Proof of concept 1 Neuron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "593db484-70f9-4f94-9c1b-f31205287294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\"\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9956790-f92a-49bc-b030-9c12984bf878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! SIMILAR CODE FROM \"demonstrating_superposition.ipynb\" !!! #\n",
    "\n",
    "class ToyModel(nn.Module):\n",
    "    def __init__(self, m, n, include_ReLU):\n",
    "        '''Create a toy model\n",
    "\n",
    "        Args:\n",
    "            m (int): the number of neurons (as described in original paper)\n",
    "            n (int): the number of features the Toy model can map.\n",
    "            (The weight matrix is delcared to be m * n)\n",
    "\n",
    "            include_ReLU (bool): if True, a nonlinearity is added to the network\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(m, n), requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.randn(n, 1), requires_grad=True)\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        self.inclue_ReLU = include_ReLU\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden = self.weights @ x\n",
    "        final = self.weights.T @ hidden\n",
    "        final += self.bias\n",
    "        if self.inclue_ReLU:\n",
    "            return self.ReLU(final)\n",
    "        else:\n",
    "            return final\n",
    "\n",
    "class ImporanceWeightedMSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImporanceWeightedMSE, self).__init__()\n",
    "\n",
    "    def forward(self, predictions, targets, importance):\n",
    "        sub_total = ((predictions - targets)**2).sum(0).flatten()\n",
    "        return sum(sub_total * importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62de191f-40a1-4bd5-998c-913079fe6a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! SIMILAR CODE FROM \"demonstrating_superposition.ipynb\" !!! #\n",
    "\n",
    "def train(model, epochs, total_batchs, batch_size, loss_fn, optimizer, importance, sparsity):\n",
    "    probability = 1 - sparsity\n",
    "    model.train()\n",
    "    loss_total = 0\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batchs):\n",
    "            sparsity_tensor = torch.bernoulli(torch.full((2,1), probability))\n",
    "            x = torch.rand(batch_size, 2, 1)\n",
    "            x = (x*sparsity_tensor).to(device)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, x, importance)\n",
    "            loss_total += loss.item()\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print(\"(EPOCH:\", str(epoch + 1) + \")\", \"--> loss:\", loss_total / (total_batchs * batch_size))\n",
    "        loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9451f984-91db-46bf-9027-939b43cb1d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "BATCHS_PER_EPOCH = 1000\n",
    "BATCH_SIZE = 512\n",
    "LEARNING_RATE = 5e-3\n",
    "IMPORTANCE = (0.01 ** torch.arange(0, 2)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "09422a85-387e-4452-9d0e-630f4c9f9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_99_sparsity = ToyModel(1, 2, False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0a1ce1c8-a209-4fd1-a184-3893322aac4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(EPOCH: 1) --> loss: 1.526354720722884\n",
      "(EPOCH: 2) --> loss: 0.0292441052114591\n",
      "(EPOCH: 3) --> loss: 0.009354934247909114\n",
      "(EPOCH: 4) --> loss: 0.0020913388857152315\n",
      "(EPOCH: 5) --> loss: 0.0008785506336716935\n"
     ]
    }
   ],
   "source": [
    "SPARSITY = 0.0\n",
    "optimizer = torch.optim.Adam(model_99_sparsity.parameters(), lr=LEARNING_RATE)\n",
    "loss_func = ImporanceWeightedMSE()\n",
    "\n",
    "train(model_99_sparsity, NUM_EPOCHS, BATCHS_PER_EPOCH, BATCH_SIZE, loss_func, optimizer, IMPORTANCE, SPARSITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "607e24db-1329-484b-bbee-376154e77c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.9991, -0.0034]], device='mps:0', requires_grad=True)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_99_sparsity.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2dbfe224-fe87-4fb9-b867-d900285dffec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.0027],\n",
       "        [0.5011]], device='mps:0', requires_grad=True)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_99_sparsity.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ea83c6-e5da-46e0-85e9-949c6f2c37c5",
   "metadata": {},
   "source": [
    "# Training 1 Neuron Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "9c3c0bec-9715-4cb9-b234-99a009490cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManyToyModels(nn.Module):\n",
    "    def __init__(self, m, n, num_models, include_ReLU):\n",
    "        '''Create a toy model\n",
    "\n",
    "        Args:\n",
    "            m (int): the number of neurons (as described in original paper)\n",
    "            n (int): the number of features the Toy model can map.\n",
    "            (The weight matrix is delcared to be m * n)\n",
    "\n",
    "            include_ReLU (bool): if True, a nonlinearity is added to the network\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(num_models, m, n), requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.randn(num_models, n, 1), requires_grad=True)\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        self.inclue_ReLU = include_ReLU\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden = self.weights @ x\n",
    "        final = torch.transpose(self.weights, -2, -1) @ hidden\n",
    "        final += self.bias\n",
    "        if self.inclue_ReLU:\n",
    "            return self.ReLU(final)\n",
    "        else:\n",
    "            return final\n",
    "\n",
    "class MSE_Multiple_models(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MSE_Multiple_models, self).__init__()\n",
    "\n",
    "    def forward(self, predictions, targets, importance):\n",
    "        sub_total = ((predictions - targets)**2).sum(0)\n",
    "        return torch.sum(sub_total * importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "e990551d-8196-45b6-9f06-87b25a5c71dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_1000_models(model, num_models, epochs, total_batchs, batch_size, loss_fn, optimizer, importance, sparsity):\n",
    "    probability = 1 - sparsity\n",
    "    model.train()\n",
    "    loss_total = 0\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batchs):\n",
    "            sparsity_tensor = torch.bernoulli(torch.full((2 ,1), probability))\n",
    "            x = torch.rand(batch_size, num_models, 2, 1)\n",
    "            x = (x*sparsity_tensor).to(device)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, x, importance)\n",
    "            loss_total += loss.item()\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print(\"(EPOCH:\", str(epoch + 1) + \")\", \"--> loss:\", loss_total / (total_batchs * batch_size))\n",
    "        loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "7b9ee70b-9b7e-4af6-ac43-d04afc3ff0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = ManyToyModels(1, 2, 100000, False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "cf5413c0-5d1d-4276-9ecc-3215349174ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_test(torch.randn(1, 10, 2, 1).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "d0c8275e-8bb1-4eab-9484-26650bc02aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "BATCHS_PER_EPOCH = 100\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "426229d2-970a-4682-a1a6-4deb78a3ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_feature_importance = torch.ones(100000, 1)\n",
    "second_feature_importance = (torch.repeat_interleave(torch.arange(100), 1000) / 10).reshape(100000, 1)\n",
    "IMPORTANCE = torch.stack((first_feature_importance, second_feature_importance), dim=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "3c7dd8e5-fef0-4cc8-a777-9bb5686ca0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(EPOCH: 1) --> loss: 25152.643125\n",
      "(EPOCH: 2) --> loss: 15994.9673828125\n",
      "(EPOCH: 3) --> loss: 12356.544306640624\n",
      "(EPOCH: 4) --> loss: 10536.60732421875\n",
      "(EPOCH: 5) --> loss: 9547.62083984375\n",
      "(EPOCH: 6) --> loss: 8963.6928515625\n",
      "(EPOCH: 7) --> loss: 8597.260400390625\n",
      "(EPOCH: 8) --> loss: 8364.539130859375\n",
      "(EPOCH: 9) --> loss: 8217.306850585937\n",
      "(EPOCH: 10) --> loss: 8119.491166992188\n",
      "(EPOCH: 11) --> loss: 8057.835107421875\n",
      "(EPOCH: 12) --> loss: 8015.707998046875\n",
      "(EPOCH: 13) --> loss: 7986.529350585937\n",
      "(EPOCH: 14) --> loss: 7966.891865234375\n",
      "(EPOCH: 15) --> loss: 7951.86802734375\n",
      "(EPOCH: 16) --> loss: 7942.048310546875\n",
      "(EPOCH: 17) --> loss: 7932.562124023438\n",
      "(EPOCH: 18) --> loss: 7926.081518554687\n",
      "(EPOCH: 19) --> loss: 7922.313188476563\n",
      "(EPOCH: 20) --> loss: 7917.801254882813\n"
     ]
    }
   ],
   "source": [
    "SPARSITY = 0.0\n",
    "optimizer = torch.optim.Adam(model_test.parameters(), lr=LEARNING_RATE)\n",
    "loss_func = MSE_Multiple_models()\n",
    "num_models = 100000\n",
    "\n",
    "train_1000_models(model_test, num_models, NUM_EPOCHS, BATCHS_PER_EPOCH, BATCH_SIZE, loss_func, optimizer, IMPORTANCE, SPARSITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "77b076e6-0126-4075-b825-bebbd074602e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[-1.0000e+00, -2.0149e-10]],\n",
       "\n",
       "        [[ 1.0000e+00,  4.2285e-08]],\n",
       "\n",
       "        [[ 1.0000e+00, -8.7737e-12]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 6.4922e-03, -9.9975e-01]],\n",
       "\n",
       "        [[-3.8078e-03, -1.0016e+00]],\n",
       "\n",
       "        [[-5.0459e-03,  1.0027e+00]]], device='mps:0', requires_grad=True)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a24e086-99dc-4201-a21e-423c9d187303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
